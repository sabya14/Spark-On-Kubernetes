version: '2.2'
services:
  spark-master:
    image: bde2020/spark-master:2.4.5-hadoop2.7
    container_name: spark-master
    ports:
      - "8080:8080"
      - "7077:7077"
    environment:
      - INIT_DAEMON_STEP=setup_spark
    volumes:
      - ../data:/data

  spark-worker-1:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    volumes:
      - ../data:/data

  spark-worker-2:
    image: bde2020/spark-worker:2.4.5-hadoop2.7
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
    volumes:
      - ../data:/data


  spark-application:
    build:
      context: ../
      dockerfile: docker/Dockerfile
    container_name: spark-application
    ports:
      - "8080:8080" # spark master
      - "7077:7077" #
    environment:
      ENABLE_INIT_DAEMON: "false"
      SPARK_APPLICATION_MAIN_CLASS: data_transformer.Transformer
      SPARK_APPLICATION_ARGS: /var/data/test.csv /var/data/output.csv
    volumes:
      - ${PWD}/data:/var/data